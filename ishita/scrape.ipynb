{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "898cde40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for riga in 2021...\n",
      "Could not find the table containing weather data.\n",
      "Failed to scrape data for riga in 2021.\n",
      "Scraping data for riga in 2022...\n",
      "Could not find the table containing weather data.\n",
      "Failed to scrape data for riga in 2022.\n",
      "Scraping data for riga in 2023...\n",
      "Could not find the table containing weather data.\n",
      "Failed to scrape data for riga in 2023.\n",
      "Scraping data for riga in 2024...\n",
      "Could not find the table containing weather data.\n",
      "Failed to scrape data for riga in 2024.\n",
      "No data was scraped.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "def scrape_weather_data(city, year):\n",
    "    \"\"\"\n",
    "    Scrapes weather data from Weather Underground for a given city and year.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city.\n",
    "        year (int): The year for which to scrape data.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the scraped weather data, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.wunderground.com/history/daily/{city}/date/{year}-1\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses (4XX, 5XX)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during requests to {url} : {e}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    table = soup.find(\"lib-city-history-observation\").find(\n",
    "        \"table\", class_=\"mat-table cdk-table\"\n",
    "    )\n",
    "    if not table:\n",
    "        print(\"Could not find the table containing weather data.\")\n",
    "        return None\n",
    "\n",
    "    headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "    data = []\n",
    "\n",
    "    for tr in table.find(\"tbody\").find_all(\"tr\"):\n",
    "        row = [td.text.strip() for td in tr.find_all(\"td\")]\n",
    "        data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    return df\n",
    "\n",
    "\n",
    "def main(city, start_year, end_year):\n",
    "    \"\"\"\n",
    "    Scrapes and combines weather data for a city across a range of years.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city to scrape data for.\n",
    "        start_year (int): The first year to scrape data from.\n",
    "        end_year (int): The last year to scrape data from.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        print(f\"Scraping data for {city} in {year}...\")\n",
    "        df = scrape_weather_data(city, year)\n",
    "        if df is not None:\n",
    "            all_data.append(df)\n",
    "            print(f\"Successfully scraped data for {city} in {year}.\")\n",
    "            time.sleep(5)  # Be nice to the server\n",
    "        else:\n",
    "            print(f\"Failed to scrape data for {city} in {year}.\")\n",
    "\n",
    "    if all_data:\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        combined_df.to_csv(f\"{city}_weather_{start_year}_{end_year}.csv\", index=False)\n",
    "        print(\n",
    "            f\"Data for {city} from {start_year} to {end_year} has been saved to {city}_weather_{start_year}_{end_year}.csv\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"No data was scraped.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    city = \"riga\"  # Replace with the desired city\n",
    "    start_year = 2021\n",
    "    end_year = 2024\n",
    "    main(city, start_year, end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6373b137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
